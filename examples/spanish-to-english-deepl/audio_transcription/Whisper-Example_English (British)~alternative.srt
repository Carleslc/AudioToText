1
00:00:00,000 --> 00:00:06,040
2022 will be remembered as the year of Stable Diffusion, of Dali 2, of incredible models

2
00:00:06,040 --> 00:00:10,160
text generators such as Palm or code generators such as AlphaCode.

3
00:00:10,160 --> 00:00:13,920
And yet, chatting last month with AndrÃ©s Torrubia, he told me that the

4
00:00:13,920 --> 00:00:18,120
most interesting thing I'd seen this year was an artificial intelligence that was coming

5
00:00:18,120 --> 00:00:21,880
from the OpenAI lab, an AI called Whisper.

6
00:00:21,880 --> 00:00:26,880
What do you think is the most impressive thing that has come out this year?

7
00:00:26,880 --> 00:00:31,800
Well, oddly enough, look, oddly enough, so far Whisper, I think.

8
00:00:31,800 --> 00:00:32,800
Do you know why?

9
00:00:32,800 --> 00:00:33,800
Curious, eh.

10
00:00:33,800 --> 00:00:39,760
What impresses me about Whisper is that Whisper works, it's like, for me, Whisper, if it were

11
00:00:39,760 --> 00:00:46,880
the autonomous car, it would be the first self-driving car in the dictation, i.e. it is the first one that resembles

12
00:00:46,880 --> 00:00:47,880
to a person.

13
00:00:47,880 --> 00:00:51,000
Well, but in order for you to first understand what this Whisper thing is, I'm going to ask you to

14
00:00:51,000 --> 00:00:53,120
do the following exercise.

15
00:00:53,120 --> 00:00:57,800
I am going to play you an audio in English and your task is to transcribe each of the words

16
00:00:57,800 --> 00:00:59,600
you are listening to.

17
00:00:59,600 --> 00:01:00,600
Are you ready?

18
00:01:00,600 --> 00:01:02,600
Three, two, one.

19
00:01:19,800 --> 00:01:21,280
Have you understood anything?

20
00:01:21,280 --> 00:01:22,760
Yeah, me neither.

21
00:01:22,760 --> 00:01:28,160
Well, in the ears of this artificial intelligence, this is the perfect transcription it has achieved.

22
00:01:28,160 --> 00:01:29,400
How is your Korean?

23
00:01:29,400 --> 00:01:33,680
Well, it's no problem for Whisper either, and he can also transcribe this audio at

24
00:01:33,680 --> 00:01:35,520
perfect English.

25
00:01:44,440 --> 00:01:46,080
And well, he understands me too.

26
00:01:46,080 --> 00:01:50,040
What you're seeing on the screen now is the speech to text that Whisper gets when it

27
00:01:50,040 --> 00:01:52,680
I pass on the audio track you are listening to.

28
00:01:52,680 --> 00:01:57,440
Look closely, not only does he get a near-perfect transcription, understanding even words

29
00:01:57,440 --> 00:02:02,760
such as Whisper or speech to text, but it is also capable of generating full stops, commas

30
00:02:02,760 --> 00:02:06,560
and other punctuation marks than many other commercial recognition models

31
00:02:06,560 --> 00:02:08,360
of speech as he tends to choke on it.

32
00:02:08,360 --> 00:02:10,720
And this is very interesting.

33
00:02:10,720 --> 00:02:12,960
Well, not this, but Whisper.

34
00:02:12,960 --> 00:02:18,160
Whisper in general has many interesting things and the first interesting thing is the context

35
00:02:18,160 --> 00:02:20,120
in which this tool appears.

36
00:02:20,120 --> 00:02:23,640
After a year of amazing achievements by the Artificial Intelligence Lab

37
00:02:23,640 --> 00:02:29,680
OpenAI, suddenly out of the blue a collaborative initiative like Stability.ai

38
00:02:29,680 --> 00:02:34,320
which in September takes up the banner of making open source many of the technologies that

39
00:02:34,320 --> 00:02:40,240
OpenAI for its part has decided to keep to itself and share only under services

40
00:02:40,240 --> 00:02:41,240
payment.

41
00:02:41,240 --> 00:02:46,360
This is not a problem for me either, because in the end OpenAI as a company has

42
00:02:46,360 --> 00:02:50,720
to pay their bills and at least it's giving us a way to access these powerful

43
00:02:50,720 --> 00:02:52,360
artificial intelligences.

44
00:02:52,360 --> 00:02:53,920
Learn Google.

45
00:02:53,920 --> 00:02:57,880
But of course, a new little boy arrives in town and starts giving out sweets to the

46
00:02:57,880 --> 00:03:01,920
children and all of a sudden the popular kid starts to be displaced.

47
00:03:01,920 --> 00:03:07,760
And at that precise moment OpenAI comes out of nowhere and gives us Whisper for our benefit

48
00:03:07,760 --> 00:03:08,760
of all.

49
00:03:08,760 --> 00:03:13,580
Because yes, my friends, this is open source, and I know you love to hear these words.

50
00:03:13,580 --> 00:03:17,160
At the end of the video I'm going to show you a mini tutorial so you can see how easy it is to use

51
00:03:17,160 --> 00:03:21,000
this tool and I'm also going to share a notebook to make it super easy for you to

52
00:03:21,000 --> 00:03:22,000
you.

53
00:03:22,000 --> 00:03:25,800
And this is what makes Whisper a super interesting tool, but it is not the only thing.

54
00:03:25,800 --> 00:03:29,800
And this is where one of the things that has caught my attention is that Whisper

55
00:03:29,800 --> 00:03:34,440
is not a complex system that has been designed to process audio in a way that has never been done before

56
00:03:34,440 --> 00:03:38,640
made or a super-complex system with a lot of processing modules.

57
00:03:38,640 --> 00:03:45,840
No, Whisper is this right here, a transformer neural network from 2017, it doesn't have

58
00:03:45,840 --> 00:03:47,920
no change, nothing new.

59
00:03:47,920 --> 00:03:51,280
It is an architecture with which we are all familiar.

60
00:03:51,280 --> 00:03:55,800
So, if this is the case, why didn't a technology like Whisper already exist?

61
00:03:55,800 --> 00:04:00,800
Well, the key to what makes Whisper so powerful is in the data and how it has been used

62
00:04:00,800 --> 00:04:02,920
structured their training.

63
00:04:02,920 --> 00:04:09,040
To train him, OpenAI used no less than 680,000 hours of audio with its

64
00:04:09,040 --> 00:04:12,360
corresponding text, a brutality.

65
00:04:12,360 --> 00:04:17,200
And if you calculate 680,000 hours and start reproducing them now, you would end up with

66
00:04:17,200 --> 00:04:19,880
to listen to it 77 years from now.

67
00:04:19,880 --> 00:04:24,160
You could be sure that at some point in the sky you would see Halley's comet streaking across the sky.

68
00:04:24,160 --> 00:04:28,560
But what's more, a very interesting thing is that these audios come in multiple languages,

69
00:04:28,560 --> 00:04:32,200
allowing us to be able to train a model that is multilingual, that can understand us

70
00:04:32,200 --> 00:04:36,560
whether we speak to him in Spanish, English, Korean, it doesn't matter.

71
00:04:36,560 --> 00:04:38,240
But it doesn't stop there.

72
00:04:38,240 --> 00:04:43,720
Whisper is not only a multilingual system, but also a multitasking system.

73
00:04:43,720 --> 00:04:47,520
This is a trend that, as we saw in the video on Gato, in the world of deep

74
00:04:47,520 --> 00:04:49,760
learning is becoming more and more frequent.

75
00:04:49,760 --> 00:04:54,680
Do not train artificial intelligence for a single task, but train it for several tasks

76
00:04:54,680 --> 00:04:59,560
different, thus making their learning much more solid and robust.

77
00:04:59,560 --> 00:05:04,560
As we have seen, Whisper can take audios in English and transcribe them into English, or

78
00:05:04,560 --> 00:05:06,960
audio in Korean and transcribe it into Korean.

79
00:05:06,960 --> 00:05:11,200
But the same model can also identify which language is being spoken, or acted upon

80
00:05:11,200 --> 00:05:15,360
as a speech detector to classify when a piece of audio is not being listened to

81
00:05:15,360 --> 00:05:16,360
to a person.

82
00:05:16,360 --> 00:05:20,960
Or also, the task that I find most interesting of all, that you can talk to him or her

83
00:05:20,960 --> 00:05:25,720
to Whisper in any language and have it automatically transcribe it into English for you.

84
00:05:25,720 --> 00:05:29,800
And in this case I can't tell you why, but for me this seems to me to be one of the most important functions

85
00:05:29,800 --> 00:05:30,800
fascinating.

86
00:05:30,800 --> 00:05:32,880
It doesn't seem to offer us anything new either, does it?

87
00:05:32,880 --> 00:05:37,560
In the end you can take the text generated by any text transcriber in your language

88
00:05:37,560 --> 00:05:39,520
and run it through a translator.

89
00:05:39,520 --> 00:05:43,520
But in this case, I find it fascinating to see how something as simple as a single

90
00:05:43,520 --> 00:05:47,880
deep learning model allows you to speak to it in any language and have it generate the text for you

91
00:05:47,880 --> 00:05:51,520
in English without having to combine any tools.

92
00:05:51,520 --> 00:05:53,400
It's super simple.

93
00:05:53,400 --> 00:05:56,360
And the data we discussed earlier is also very interesting.

94
00:05:56,360 --> 00:06:00,480
Because my first intuition here is that OpenAI, in the search for a massive dataset

95
00:06:00,480 --> 00:06:05,280
of these 680,000 hours of audio to have a text transcription in order to be able to make

96
00:06:05,280 --> 00:06:09,800
this supervised apprenticeship, as he had possibly gone to one of the largest sources of

97
00:06:09,800 --> 00:06:12,520
that we can find on the Internet, which is YouTube.

98
00:06:12,520 --> 00:06:16,960
In the end you know that all YouTube videos are automatically generated with subtitles.

99
00:06:16,960 --> 00:06:17,960
Well, no.

100
00:06:17,960 --> 00:06:22,800
This is precisely what OpenAI puts a lot of emphasis on in its paper to explain what they have done

101
00:06:22,800 --> 00:06:28,200
a filtering process to remove from the dataset any text occurrences generated by

102
00:06:28,200 --> 00:06:31,000
automatic speech recognition systems.

103
00:06:31,000 --> 00:06:32,000
Why?

104
00:06:32,000 --> 00:06:36,480
It was precisely to prevent Whisper from learning those defects, those vices, too

105
00:06:36,480 --> 00:06:40,000
that other automatic systems may also have.

106
00:06:40,000 --> 00:06:44,600
That said, now that we're talking about Whisper and YouTube, there is a theory that

107
00:06:44,600 --> 00:06:48,520
I want to tell you that I think it's very interesting, it's nothing that is confirmed, but that

108
00:06:48,520 --> 00:06:53,560
could explain the reason for the existence of this tool and that it could have a certain relationship with the

109
00:06:53,560 --> 00:06:55,760
with a future GPT-4.

110
00:06:55,760 --> 00:06:59,720
This is an idea I heard on Dr. Alan Thompson's channel, which says that in

111
00:06:59,720 --> 00:07:05,600
the near future, where GPT-4 can begin training, Whisper could offer the system

112
00:07:05,600 --> 00:07:09,800
a huge source of data that previous systems had not been able to count on.

113
00:07:09,800 --> 00:07:14,640
Think of a system like GPT-3 as having been trained with a lot of Wikipedia articles,

114
00:07:14,640 --> 00:07:19,120
of books, of forums, of Internet conversations, but he has never been able to access all of the

115
00:07:19,120 --> 00:07:23,640
that spoken source that may be in databases such as YouTube.

116
00:07:23,640 --> 00:07:28,240
A tool such as Whisper could be used to sweep YouTube completely, transcribe

117
00:07:28,240 --> 00:07:33,200
many of their audios and get, unlock a new source of data that previously would not have

118
00:07:33,200 --> 00:07:37,400
It has been possible to use it to train a future language model.

119
00:07:37,400 --> 00:07:41,560
This is the enormous value of a tool like Whisper that I think makes it so interesting

120
00:07:41,560 --> 00:07:42,560
to this technology.

121
00:07:42,560 --> 00:07:47,680
No, it does not solve a task that is spectacular, such as generating images or generating video, but it does

122
00:07:47,680 --> 00:07:52,280
solves a very useful task and almost solves it to perfection.

123
00:07:52,280 --> 00:07:57,640
I say almost, it's not perfect, sometimes some words are obviously wrong and it doesn't cover it

124
00:07:57,640 --> 00:08:02,200
all the languages that exist on planet Earth, and well, to look for some limitation

125
00:08:02,200 --> 00:08:07,320
compared to other commercial tools, as it does not yet work in real time either.

126
00:08:07,320 --> 00:08:11,280
Depending on the length of the audio it can take a few seconds to process it, sometimes

127
00:08:11,280 --> 00:08:17,080
It's a solid tool, it's mature, it's useful and it's open source,

128
00:08:17,080 --> 00:08:21,040
now allowing anyone to have access to a professional transcription tool

129
00:08:21,040 --> 00:08:25,160
and text translation better than any free alternative.

130
00:08:25,160 --> 00:08:26,160
What?

131
00:08:26,160 --> 00:08:28,600
Oh, that you too would like to have access to this tool.

132
00:08:28,600 --> 00:08:32,720
Well, come on, I'll prepare an easy tutorial for all of you to use.

133
00:08:32,720 --> 00:08:37,640
We are going to do it in Google Colab, but first and taking advantage of the fact that we are talking about programming,

134
00:08:37,640 --> 00:08:41,880
of development, of innovation, let me remind you that there are very few days left

135
00:08:41,880 --> 00:08:46,880
for Samsung Dev Day, which is the technology event held every year to celebrate the Samsung

136
00:08:46,880 --> 00:08:51,760
year the Samsung Dev Spain community, which is Samsung's official community for developers

137
00:08:51,760 --> 00:08:52,840
Spanish.

138
00:08:52,840 --> 00:08:55,560
This will be a free event not to be missed.

139
00:08:55,560 --> 00:09:00,640
If you are in Madrid you can attend in person on 16th November at the cloister of

140
00:09:00,640 --> 00:09:04,840
the Hieronymites of the Museo del Prado and if not, you can connect online at

141
00:09:04,840 --> 00:09:05,840
its streaming.

142
00:09:05,840 --> 00:09:09,760
But yes, you have to register, I was lucky enough to be able to participate last year with one of my own

143
00:09:09,760 --> 00:09:14,280
presentation on code generation with artificial intelligence and the experience was

144
00:09:14,280 --> 00:09:15,280
great.

145
00:09:15,280 --> 00:09:18,800
So you see, it's going to be an event full of great talks, talking about technology,

146
00:09:18,800 --> 00:09:23,280
of innovation, of applications, and it will also be presented by my dudev, who will surely

147
00:09:23,280 --> 00:09:26,560
Many of you will know him, so you can't miss him.

148
00:09:26,560 --> 00:09:30,320
I'll leave a link to the Samsung Dev website below in the description box

149
00:09:30,320 --> 00:09:35,160
Spain, where you will find all the information regarding the agenda where you can register and a

150
00:09:35,160 --> 00:09:37,040
a lot of other resources.

151
00:09:37,040 --> 00:09:38,720
See you on 16 November.

152
00:09:38,720 --> 00:09:43,400
Let's see how we can use Whisper in our own code.

153
00:09:43,400 --> 00:09:47,240
For this we are going to use Google Colab, you know that Google is giving us here

154
00:09:47,240 --> 00:09:52,080
a free virtual machine that we can use and we will check as long as we have

155
00:09:52,080 --> 00:09:56,560
enabled the GPU hardware accelerated environment type, OK, let's hit it here

156
00:09:56,560 --> 00:10:01,320
GPU, let's hit save and now the first step will be to install Whisper.

157
00:10:01,320 --> 00:10:05,600
To do this we are going to use these two commands here, to install, you can find this here

158
00:10:05,600 --> 00:10:11,160
in Whisper's own GitHub repository, I'm going to leave you below in the description box

159
00:10:11,160 --> 00:10:14,160
these commands, hit run and let it install.

160
00:10:14,160 --> 00:10:17,880
Once installed, we are going to upload some audio that we want to transcribe, in this case

161
00:10:17,880 --> 00:10:21,920
I'm going to try RosalÃ­a's song from Chicken Teriyaki, let's put it here,

162
00:10:21,920 --> 00:10:26,800
we drag it and now the next step we are going to take it here and we are going to put the command

163
00:10:26,800 --> 00:10:31,640
necessary to be able to run it, we're going to hit song.mp3 here, it's called the file that we

164
00:10:31,640 --> 00:10:37,680
we have uploaded, okay, song.mp3, so the task is going to be to transcribe the size of the model,

165
00:10:37,680 --> 00:10:42,560
there are different sizes depending on whether you want more speed when making the inference

166
00:10:42,560 --> 00:10:46,920
or if you want more precision in the results, I usually work with the Medium model

167
00:10:46,920 --> 00:10:50,600
which is the one that gives me good results, there are bigger models, there are smaller models, try it

168
00:10:50,600 --> 00:10:55,360
and in this case simply where we are going to place the output file, we run

169
00:10:55,360 --> 00:11:00,040
and that's it, that's it, no more to do, okay, we're already using Whisper,

170
00:11:00,040 --> 00:11:03,660
the first time it will take a little while because you have to download the model but from this

171
00:11:03,660 --> 00:11:08,520
At the moment you can use this system to transcribe any audio you want,

172
00:11:08,520 --> 00:11:13,640
mola, ok, we can see that in this case it has detected that the language is Spanish, it has made the inference

173
00:11:13,640 --> 00:11:16,800
automatic because we haven't told you that we are going to transcribe from Spanish, you can do it

174
00:11:16,800 --> 00:11:20,960
if you want and when this cell is already executed, we can come here, we see

175
00:11:20,960 --> 00:11:26,400
that the Audio Transcription folder has been generated and here we have the different options, we can

176
00:11:26,400 --> 00:11:32,360
open the sound.txt and here we open the file, we can see that we have the whole song perfectly

177
00:11:32,360 --> 00:11:37,000
transcribed, which in this case, being RosalÃ­a, has more merit and instead of wanting to

178
00:11:37,000 --> 00:11:41,680
transcription, you would like to make the translation, i.e. to convert your

179
00:11:41,680 --> 00:11:45,640
voice, your audio to English, so all you have to do is change here the

180
00:11:45,640 --> 00:11:51,480
task by Translate and in this case Whisper will work to translate what it has transcribed.

181
00:11:51,480 --> 00:11:54,880
In this case, if you notice, the command we have used is the console command

182
00:11:54,880 --> 00:11:58,480
but you may want to use Whisper within your code, then you can also

183
00:11:58,480 --> 00:12:02,000
you have the option to work with Whisper's own library, it's simply this one

184
00:12:02,000 --> 00:12:05,960
line of code from here, import it, load the model we want, here then

185
00:12:05,960 --> 00:12:10,960
I would load the Medium model which is the one that, as I said, works best for my case, and with

186
00:12:10,960 --> 00:12:17,520
the loaded model then here we call model.transcribe, let's put here song.mp3, we hit run

187
00:12:17,520 --> 00:12:20,880
and in a matter of seconds we will have our transcript back.

188
00:12:20,880 --> 00:12:24,520
And here it is, the Rosalia, pink without a card, I send it to your cat, I have it for you

189
00:12:24,520 --> 00:12:27,600
with roulette, no need for a serenade, ok.

190
00:12:27,600 --> 00:12:31,480
However, to make your life easier, I have prepared a notebook that you can use,

191
00:12:31,480 --> 00:12:35,000
is below in the description box, where you already have all the code ready for

192
00:12:35,000 --> 00:12:39,200
to start working, just log in, check that the GPU is activated,

193
00:12:39,200 --> 00:12:43,080
click on this button here to install everything necessary, here we choose the

194
00:12:43,080 --> 00:12:47,680
task we want to do, whether it is transcribing into any language or translating into English

195
00:12:47,680 --> 00:12:48,800
and click on run.

196
00:12:48,800 --> 00:12:53,520
In this case the cell is prepared so that the moment you start to run it

197
00:12:53,520 --> 00:12:57,080
your microphone is recording right now, i.e. right now we would be generating

198
00:12:57,080 --> 00:13:00,960
an audio file that we will then use for transcribing with Whisper, this is by

199
00:13:00,960 --> 00:13:05,480
if you want to make a real-time transcript of any class or anything else

200
00:13:05,480 --> 00:13:06,480
you need.

201
00:13:06,480 --> 00:13:10,800
We're going to hit stop, we hit this button and in a moment we have the result of what we've done

202
00:13:10,800 --> 00:13:12,520
we have said.

203
00:13:12,520 --> 00:13:16,800
Below you will find the two commands needed to be able to transcribe or translate

204
00:13:16,800 --> 00:13:19,240
the audio you upload.

205
00:13:19,240 --> 00:13:22,760
Finally, you should also know that if you want something simpler, then there are pages

206
00:13:22,760 --> 00:13:27,240
website where you can try out this system by uploading your own audios or by recording

207
00:13:27,240 --> 00:13:28,240
from the microphone.

208
00:13:28,240 --> 00:13:32,960
And this would be, 2022 is shaping up to be a spectacular year in terms of numbers

209
00:13:32,960 --> 00:13:37,360
of neural toys that are coming into our hands to build a whole bunch

210
00:13:37,360 --> 00:13:39,320
and to be able to touch them.

211
00:13:39,320 --> 00:13:41,640
Now it's your turn, what can you do about it?

212
00:13:41,640 --> 00:13:45,080
Well, you can build a lot of super interesting things, you can connect by

213
00:13:45,080 --> 00:13:49,960
example Whisper with Stable Diffusion so that you can loudly ask it to

214
00:13:49,960 --> 00:13:54,040
generate a table or you can for example take all your classes at the university or

215
00:13:54,040 --> 00:13:58,960
all working meetings, transcribing them, creating a huge bank of transcripts and

216
00:13:58,960 --> 00:14:03,680
then with the GPT-3 API to make a chatbot that allows you to query, ask questions

217
00:14:03,680 --> 00:14:06,160
and answers on all these sources of information.

218
00:14:06,160 --> 00:14:10,040
For example, something I want to do is to take all the videos from my YouTube channel

219
00:14:10,040 --> 00:14:14,640
and transcribe it, generate good quality subtitles in both Spanish and English

220
00:14:14,640 --> 00:14:18,920
and to be able to make statistics and queries on how many times I have said for example the word

221
00:14:18,920 --> 00:14:19,920
Machine Learning.

222
00:14:19,920 --> 00:14:23,360
There are a lot of applications that you can start to build, that you can start to build, that you can start to

223
00:14:23,360 --> 00:14:27,160
create by combining all these technologies.

224
00:14:27,160 --> 00:14:29,880
I had a dog barking in the background that was bothering me a lot.

225
00:14:29,880 --> 00:14:34,080
Well, as I was saying, you can create a lot of things and there is a lot to do.

226
00:14:34,080 --> 00:14:37,560
From here, from this channel, we will continue to experiment with this technology,

227
00:14:37,560 --> 00:14:42,320
I will continue to bring you new tools so if you haven't done so yet, please subscribe,

228
00:14:42,320 --> 00:14:46,000
click on the little bell to always receive notifications of new videos

229
00:14:46,000 --> 00:14:50,440
and if you want to support all this content you know you can do so through Patreon

230
00:14:50,440 --> 00:14:52,080
below in the description box.

231
00:14:52,080 --> 00:14:55,080
You have a couple of videos around here that are super interesting, I don't know what they are but

232
00:14:55,080 --> 00:14:58,960
are super interesting, keep an eye on them and we'll see you with more artificial intelligence

233
00:14:58,960 --> 00:15:26,280
guys, girls, in the next video.

