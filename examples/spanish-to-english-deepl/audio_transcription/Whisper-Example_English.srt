1
00:00:00,000 --> 00:00:06,400
2022 will be remembered as the year of stable diffusion, of Dali 2, of incredible text

2
00:00:06,400 --> 00:00:11,840
generators models like Palm or code generators like AlphaCode. And yet, talking last month

3
00:00:11,840 --> 00:00:16,880
with Andres Torrubia, he told me that the most interesting thing he had seen this year was an

4
00:00:16,880 --> 00:00:22,400
artificial intelligence that came from the OpenAI laboratory, an AI called Whisper.

5
00:00:22,400 --> 00:00:26,560
What is the most impressive thing that has come out this year for you?

6
00:00:26,560 --> 00:00:32,560
Well, curiously, until now, Whisper, I think. Do you know why?

7
00:00:32,560 --> 00:00:33,280
Curious, huh?

8
00:00:33,280 --> 00:00:39,840
What impresses me about Whisper is that Whisper works, it's like, for me, Whisper, if it were the

9
00:00:39,840 --> 00:00:47,680
autonomous car, would be the first self-driving of the dictatorship. It is the first that looks like a person.

10
00:00:47,680 --> 00:00:53,040
Well, but for you to understand first what this Whisper is, I'm going to ask you to do the following exercise.

11
00:00:53,040 --> 00:00:59,520
I'm going to play an audio in English and your task is to transcribe each of the words you're listening to.

12
00:00:59,520 --> 00:01:02,320
Are you ready? 3, 2, 1.

13
00:01:19,680 --> 00:01:21,200
Have you understood anything?

14
00:01:21,200 --> 00:01:22,560
Yeah, me neither.

15
00:01:22,560 --> 00:01:28,080
Well, hearing this artificial intelligence, this is the perfect transcription you've got.

16
00:01:28,080 --> 00:01:29,280
And how about your Korean?

17
00:01:29,280 --> 00:01:35,520
Well, for Whisper it's not a problem either and you can also transcribe this audio in perfect English.

18
00:01:44,320 --> 00:01:45,760
And well, you understand me too.

19
00:01:45,760 --> 00:01:52,480
What you are seeing on the screen now is the speech to text that Whisper gets when he passes the audio track you are listening to.

20
00:01:52,480 --> 00:02:00,080
Look closely, not only does it get an almost perfect transcription, even understanding concrete words like Whisper or speech to text,

21
00:02:00,080 --> 00:02:08,320
but it is also able to generate points, commas and other punctuation marks that many other speech recognition commercial models are usually fed.

22
00:02:08,320 --> 00:02:10,640
And this is very interesting.

23
00:02:10,640 --> 00:02:12,560
Well, not this, but Whisper.

24
00:02:12,560 --> 00:02:15,680
Whisper in general has many interesting things.

25
00:02:15,680 --> 00:02:19,840
And the first interesting thing is the context in which this tool appears.

26
00:02:19,840 --> 00:02:24,800
After a year of incredible achievements by the OpenAI artificial intelligence laboratory,

27
00:02:24,800 --> 00:02:32,800
suddenly a collaborative initiative like Stability.ai emerges, which in September takes the lead in making Open Source

28
00:02:32,800 --> 00:02:40,800
many of the technologies that OpenAI, for its part, has decided to keep to itself and share only under paid services.

29
00:02:40,800 --> 00:02:47,440
For me this is not a problem either, since in the end OpenAI as a company has to pay its bills

30
00:02:47,440 --> 00:02:52,080
and at least it is giving us a way to access these powerful artificial intelligences.

31
00:02:52,080 --> 00:02:53,520
Learn Google.

32
00:02:53,520 --> 00:03:01,840
But of course, a new boy arrives in the city and begins to give candy to the children and suddenly the popular boy begins to look displaced.

33
00:03:01,840 --> 00:03:06,880
And at that precise moment, OpenAI arrives out of nowhere and gives us Whisper.

34
00:03:06,880 --> 00:03:08,320
For everyone's benefit.

35
00:03:08,320 --> 00:03:11,280
Because yes, friends, this is Open Source.

36
00:03:11,280 --> 00:03:13,280
I know you love to hear these words.

37
00:03:13,280 --> 00:03:17,680
At the end of the video I will show you a mini tutorial so you can see how easy it is to use this tool

38
00:03:17,680 --> 00:03:21,440
and I will also share a notebook so that it is super simple for you.

39
00:03:21,440 --> 00:03:24,320
And this is what makes Whisper a super interesting tool.

40
00:03:24,320 --> 00:03:25,680
But it's not the only thing.

41
00:03:25,680 --> 00:03:28,720
And this is where one of the things that has caught my attention the most comes from.

42
00:03:28,720 --> 00:03:34,960
And it is that Whisper is not a complex system that they have designed to process audio as it had never been done before,

43
00:03:34,960 --> 00:03:38,720
or a super complex system with a lot of processing modules.

44
00:03:38,720 --> 00:03:39,360
No.

45
00:03:39,360 --> 00:03:45,520
Whisper is this here, a transformer-type neural network from 2017.

46
00:03:45,520 --> 00:03:47,520
It has no change, no novelty.

47
00:03:47,520 --> 00:03:51,040
It is an architecture that we all know.

48
00:03:51,040 --> 00:03:55,440
So if this is so, why didn't a technology like Whisper already exist?

49
00:03:55,440 --> 00:04:02,640
Well, the key to making Whisper something so powerful is in the data and how they have structured their training.

50
00:04:02,640 --> 00:04:10,640
To train it, OpenAI has used no more or less than 680,000 hours of audio with its corresponding text.

51
00:04:10,640 --> 00:04:12,240
A brutality.

52
00:04:12,240 --> 00:04:19,760
And if you do the calculation, 680,000 hours, if you started playing them now, you would end up listening to it in 77 years.

53
00:04:19,760 --> 00:04:23,920
You could be sure that at some point in time you would see the comet Halley.

54
00:04:23,920 --> 00:04:28,240
But it is also a very interesting thing, is that these audios come in multiple languages,

55
00:04:28,240 --> 00:04:35,280
allowing us to train a model that is multilingual, that can understand us if we speak it in Spanish, English, Korean...

56
00:04:35,280 --> 00:04:36,320
It doesn't matter.

57
00:04:36,320 --> 00:04:38,320
But the thing is not just there.

58
00:04:38,320 --> 00:04:43,440
And it is that Whisper, in addition to being a multilingual system, is also a multitasking system.

59
00:04:43,440 --> 00:04:49,600
This is a trend that, as we saw in the video about Gato, is increasingly frequent in the world of deep learning.

60
00:04:49,600 --> 00:04:55,520
Not train AI for a single task, but train it for several different ones.

61
00:04:55,520 --> 00:04:59,360
Thus making its learning much more solid and robust.

62
00:04:59,360 --> 00:05:03,920
As we have seen, Whisper can take English audios and transcribe them to English.

63
00:05:03,920 --> 00:05:06,560
Or Korean audios and transcribe them to Korean.

64
00:05:06,560 --> 00:05:10,560
But the same model can also identify which language is being spoken.

65
00:05:10,560 --> 00:05:16,320
Or act as a voice detector to classify when a piece of audio is being heard, not a person.

66
00:05:16,320 --> 00:05:19,760
Or also the most interesting task, I think, of all.

67
00:05:19,760 --> 00:05:25,520
That you can speak to Whisper in any language and that he automatically transcribes it to English.

68
00:05:25,520 --> 00:05:30,640
And in this case I would not know why, but for me this seems to me a fascinating functionality.

69
00:05:30,640 --> 00:05:32,800
It seems that it does not offer us anything new, right?

70
00:05:32,800 --> 00:05:39,200
In the end you can take the text that any text transcriber generates in your language and pass it through a translator.

71
00:05:39,200 --> 00:05:44,480
But in this case it seems fascinating to me to see how something as simple as a single deep learning model

72
00:05:44,480 --> 00:05:51,200
allows you to speak in any language and that it generates the text in English without having to combine any type of tools.

73
00:05:51,200 --> 00:05:53,200
It's super simple.

74
00:05:53,200 --> 00:05:56,160
And the data we have commented on before is also super interesting.

75
00:05:56,160 --> 00:06:03,120
Because my first intuition here is that OpenAI, in the search for a massive data set of these 680,000 hours of audio

76
00:06:03,120 --> 00:06:06,960
that had a text transcription to be able to do this supervised learning,

77
00:06:06,960 --> 00:06:12,400
possibly had gone to one of the largest sources we can find on the internet, which is YouTube.

78
00:06:12,400 --> 00:06:16,960
In the end, you already know that all YouTube videos have automatically generated subtitles.

79
00:06:16,960 --> 00:06:17,760
Well, no.

80
00:06:17,760 --> 00:06:24,080
In this OpenAI emphasizes a lot in its paper to explain to us that they have made a filtering process

81
00:06:24,080 --> 00:06:30,880
to remove any text from the data set generated by automatic speech recognition systems.

82
00:06:30,880 --> 00:06:31,520
Why?

83
00:06:31,520 --> 00:06:39,840
Well, precisely to prevent Whisper from learning those defects, those vices that other automatic systems could also have.

84
00:06:39,840 --> 00:06:43,360
That said, now that we are talking about Whisper and YouTube,

85
00:06:43,360 --> 00:06:48,000
there is a theory that I want to tell you that I find very interesting, it is nothing that is confirmed,

86
00:06:48,000 --> 00:06:55,440
but that could explain the reason for the existence of this tool and that could have a certain relationship with a future GPT-4.

87
00:06:55,440 --> 00:07:00,640
This is an idea that I heard on the channel of Dr. Alan Thompson and that says that in the near future,

88
00:07:00,640 --> 00:07:07,040
where GPT-4 can start training, Whisper could offer the system a huge source of data

89
00:07:07,040 --> 00:07:09,840
that previous systems had not counted on.

90
00:07:09,840 --> 00:07:14,560
Let's think that a system like GPT-3 has been trained with a lot of Wikipedia articles,

91
00:07:14,560 --> 00:07:17,440
books, forums, internet conversations,

92
00:07:17,440 --> 00:07:23,440
but it has never been able to access all that spoken source that can be on databases such as YouTube.

93
00:07:23,440 --> 00:07:27,600
A tool like Whisper could be used to completely erase YouTube,

94
00:07:27,600 --> 00:07:32,400
transcribe many of its audios and unlock a new source of data

95
00:07:32,400 --> 00:07:37,040
that would not have been possible to use before to train a future language model.

96
00:07:37,040 --> 00:07:39,760
This is the enormous value that a tool like Whisper has,

97
00:07:39,760 --> 00:07:42,560
and that I think makes this technology so interesting.

98
00:07:42,560 --> 00:07:47,520
No, it does not solve a task that is spectacular, such as generating images or generating videos,

99
00:07:47,520 --> 00:07:52,400
but it solves a very useful task and almost solves it to perfection.

100
00:07:52,400 --> 00:07:56,720
Be careful, I say almost, it is not perfect, sometimes some words are obviously wrong

101
00:07:56,720 --> 00:08:00,640
and it does not cover all the languages ​​that exist on planet Earth,

102
00:08:00,640 --> 00:08:03,840
and well, for looking for some limitation compared to other commercial tools,

103
00:08:03,840 --> 00:08:06,080
it does not work in real time either.

104
00:08:06,080 --> 00:08:08,960
Still, processing audio, depending on the length,

105
00:08:08,960 --> 00:08:12,240
can take a few seconds, sometimes a minute,

106
00:08:12,240 --> 00:08:15,040
but it is a solid tool, it is mature, it is useful.

107
00:08:15,040 --> 00:08:18,400
And also open source, allowing anyone now

108
00:08:18,400 --> 00:08:22,400
can access a professional transcription and translation tool

109
00:08:22,400 --> 00:08:25,520
better than any free alternative.

110
00:08:25,520 --> 00:08:28,480
What? Oh, you also want to access this tool?

111
00:08:28,480 --> 00:08:32,480
Well, come on, I'll prepare an easy tutorial for you so you can all use it,

112
00:08:32,480 --> 00:08:34,000
we will do it in Google Colab.

113
00:08:34,000 --> 00:08:37,520
But before, and taking advantage of the fact that we are talking about programming,

114
00:08:37,520 --> 00:08:41,920
development, innovation, let me remind you that there are very few days left

115
00:08:41,920 --> 00:08:44,800
for the Samsung Dev Day to be celebrated,

116
00:08:44,800 --> 00:08:49,280
which is the technological event that the Samsung Dev Spain community celebrates every year,

117
00:08:49,280 --> 00:08:52,800
which is the official Samsung community for Spanish developers.

118
00:08:52,800 --> 00:08:55,520
This will be a free event that you cannot miss.

119
00:08:55,520 --> 00:08:59,760
If you are in Madrid, you can attend in person on November 16

120
00:08:59,760 --> 00:09:02,480
at the Clostro de los Jerónimos of the Museo del Prado.

121
00:09:02,480 --> 00:09:05,520
And if not, you can connect online through its streaming.

122
00:09:05,520 --> 00:09:07,440
But yes, you have to register.

123
00:09:07,440 --> 00:09:09,520
I was lucky last year to be able to participate

124
00:09:09,520 --> 00:09:13,120
with a paper on the generation of code with artificial intelligence

125
00:09:13,120 --> 00:09:14,800
and the experience was great.

126
00:09:14,800 --> 00:09:17,520
So you see, it will be an event full of great talks,

127
00:09:17,520 --> 00:09:20,480
talking about technology, innovation, applications,

128
00:09:20,480 --> 00:09:22,720
and it will also be presented by my Dudef,

129
00:09:22,720 --> 00:09:25,280
which surely many of you know him,

130
00:09:25,280 --> 00:09:26,560
so you can't miss it.

131
00:09:26,560 --> 00:09:28,800
I'll leave you a link in the description box

132
00:09:28,800 --> 00:09:30,720
to the Samsung Dev Spain website,

133
00:09:30,720 --> 00:09:33,600
where you will find all the information regarding the agenda,

134
00:09:33,600 --> 00:09:36,880
where to register and a lot of other resources.

135
00:09:36,880 --> 00:09:38,800
See you on November 16.

136
00:09:38,800 --> 00:09:43,200
Well, let's see how we can use Whisper in our own code.

137
00:09:43,200 --> 00:09:45,360
For this, we are going to use Google Call App.

138
00:09:45,360 --> 00:09:48,800
You already know that Google is giving us a free virtual machine

139
00:09:48,800 --> 00:09:50,880
that we can use and we are going to verify

140
00:09:50,880 --> 00:09:53,520
whenever we have activated the type of environment

141
00:09:53,520 --> 00:09:55,520
with hardware acceleration GPU.

142
00:09:55,520 --> 00:09:56,800
Okay, let's give it here.

143
00:09:56,800 --> 00:09:58,240
GPU, let's save it.

144
00:09:58,240 --> 00:10:01,040
And now the first step will be to install Whisper.

145
00:10:01,040 --> 00:10:04,160
For this, we are going to use these two commands here.

146
00:10:04,160 --> 00:10:08,560
Install, you can find this in the GitHub Whisper repository itself.

147
00:10:08,560 --> 00:10:10,800
I'll leave you down in the description box.

148
00:10:10,800 --> 00:10:14,000
These commands, we give it to run and let it install.

149
00:10:14,000 --> 00:10:16,160
Once installed, we are going to upload some audio

150
00:10:16,160 --> 00:10:17,200
that we want to transcribe.

151
00:10:17,200 --> 00:10:19,600
In this case, I'm going to try with the song of Rosalia

152
00:10:19,600 --> 00:10:20,640
by Chicken Teriyaki.

153
00:10:20,640 --> 00:10:22,560
Let's put it here, we drag it.

154
00:10:22,560 --> 00:10:25,040
And now the next step, we're going to take it here

155
00:10:25,040 --> 00:10:28,320
and we're going to put the command we need to run it.

156
00:10:28,320 --> 00:10:30,720
We're going to give it here to song.mp3.

157
00:10:30,720 --> 00:10:32,560
It's called the file we've uploaded.

158
00:10:32,560 --> 00:10:34,640
Okay, song.mp3.

159
00:10:34,640 --> 00:10:37,520
The task is going to be to transcribe the size of the model.

160
00:10:37,520 --> 00:10:38,560
There are different sizes,

161
00:10:38,560 --> 00:10:42,400
depending on whether you want more speed when doing the inference

162
00:10:42,400 --> 00:10:44,960
or if you want more precision in the results.

163
00:10:44,960 --> 00:10:46,800
I usually work with the medium model,

164
00:10:46,800 --> 00:10:48,320
which is the one that gives me good results.

165
00:10:48,320 --> 00:10:50,000
There are larger models, there are smaller models.

166
00:10:50,000 --> 00:10:50,480
Try it.

167
00:10:50,480 --> 00:10:54,320
And in this case, we're just going to put the output file.

168
00:10:54,320 --> 00:10:56,000
We run it and that's it.

169
00:10:56,000 --> 00:10:56,480
That's it.

170
00:10:56,480 --> 00:10:57,840
There's nothing else to do.

171
00:10:57,840 --> 00:10:59,840
Okay, we're using Whisper.

172
00:10:59,840 --> 00:11:01,520
The first time it will take a while

173
00:11:01,520 --> 00:11:02,800
because it has to download the model,

174
00:11:02,800 --> 00:11:04,080
but from this moment on,

175
00:11:04,080 --> 00:11:06,480
you can use this system to transcribe

176
00:11:06,480 --> 00:11:08,560
any audio you want.

177
00:11:08,560 --> 00:11:09,200
Cool.

178
00:11:09,200 --> 00:11:11,040
Okay, we see that in this case it has detected

179
00:11:11,040 --> 00:11:12,400
that the language is Spanish.

180
00:11:12,400 --> 00:11:14,080
It has made the automatic inference

181
00:11:14,080 --> 00:11:16,160
because we have not told it that we are going to transcribe in Spanish.

182
00:11:16,160 --> 00:11:17,440
You can do it if you want.

183
00:11:17,440 --> 00:11:19,040
And when this cell is already executed,

184
00:11:19,040 --> 00:11:20,480
we can come over here.

185
00:11:20,480 --> 00:11:23,040
We see that the audio transcription folder has been generated

186
00:11:23,040 --> 00:11:25,840
and here we have the different options.

187
00:11:25,840 --> 00:11:28,000
We can open the sound.txt

188
00:11:28,000 --> 00:11:29,120
and here we open the file.

189
00:11:29,120 --> 00:11:32,800
We see that we have the whole song perfectly transcribed,

190
00:11:32,800 --> 00:11:35,600
which in this case, being Rosalía, has more merit.

191
00:11:35,600 --> 00:11:38,000
If instead of wanting to do the transcription,

192
00:11:38,000 --> 00:11:40,000
you would like to do the translation,

193
00:11:40,000 --> 00:11:43,840
that is, convert your voice, your audio to English,

194
00:11:43,840 --> 00:11:46,800
then all you have to do is change the task here for translate.

195
00:11:46,800 --> 00:11:49,840
And in this case, Whisper will work to translate

196
00:11:49,840 --> 00:11:51,360
what it has transcribed.

197
00:11:51,360 --> 00:11:52,480
In this case, if you notice,

198
00:11:52,480 --> 00:11:54,880
the command we have used has been the console one,

199
00:11:54,880 --> 00:11:57,920
but maybe you want to use Whisper within your code.

200
00:11:57,920 --> 00:11:59,440
Then you also have the option of working

201
00:11:59,440 --> 00:12:01,040
with the Whisper library itself.

202
00:12:01,040 --> 00:12:03,120
It's just this line of code here.

203
00:12:03,120 --> 00:12:05,360
We import it, we load the model we want.

204
00:12:05,360 --> 00:12:07,520
Here, I would load the medium model,

205
00:12:07,520 --> 00:12:10,480
which is the one that, as I say, works best for my case.

206
00:12:10,480 --> 00:12:11,600
And with the loaded model,

207
00:12:11,600 --> 00:12:14,160
then here we call model.transcribe.

208
00:12:14,160 --> 00:12:16,400
We are going to put here song.mp3.

209
00:12:16,400 --> 00:12:18,560
We hit run and in a matter of seconds,

210
00:12:18,560 --> 00:12:20,720
we will have our transcription again.

211
00:12:20,720 --> 00:12:21,440
And here we have it.

212
00:12:21,440 --> 00:12:23,920
The pink rose without a card, I send it to your cat,

213
00:12:23,920 --> 00:12:26,080
I have it with a roulette, no need to serenade.

214
00:12:26,080 --> 00:12:26,580
Well, shock.

215
00:12:27,120 --> 00:12:28,800
Also to make your life easier,

216
00:12:28,800 --> 00:12:31,120
I have prepared a notebook that you can use.

217
00:12:31,120 --> 00:12:32,960
It's down in the description box,

218
00:12:32,960 --> 00:12:35,920
where you already have all the code ready to start working.

219
00:12:35,920 --> 00:12:37,040
You just have to enter,

220
00:12:37,040 --> 00:12:38,960
check that the GPU is activated,

221
00:12:38,960 --> 00:12:42,160
we hit this button here to install everything necessary.

222
00:12:42,160 --> 00:12:44,000
Here we choose the task we want to do,

223
00:12:44,000 --> 00:12:47,520
because if it is to transcribe to any language or translate to English,

224
00:12:47,520 --> 00:12:48,640
and we hit run.

225
00:12:48,640 --> 00:12:50,240
In this case, the cell is prepared

226
00:12:50,240 --> 00:12:53,440
so that the moment you start to run it,

227
00:12:53,440 --> 00:12:55,120
it is recording your microphone right now.

228
00:12:55,120 --> 00:12:57,920
That is, right now we would be generating an audio file

229
00:12:57,920 --> 00:13:00,400
that we will later use to transcribe with Whisper.

230
00:13:00,400 --> 00:13:03,520
This is in case you want to make a transcription in real time

231
00:13:03,520 --> 00:13:06,160
of any class or anything you need.

232
00:13:06,160 --> 00:13:07,920
We're going to stop it, we hit this button,

233
00:13:08,560 --> 00:13:12,000
and in a moment we have the result of what we have said.

234
00:13:12,000 --> 00:13:14,800
Likewise, then below I add the two commands necessary

235
00:13:14,800 --> 00:13:18,960
to be able to transcribe or translate the audio that you upload.

236
00:13:18,960 --> 00:13:21,840
Finally, you also have to know that if you want something simpler,

237
00:13:21,840 --> 00:13:24,960
there is a website where you can try this system

238
00:13:24,960 --> 00:13:28,160
by uploading your own audios or recording from the microphone.

239
00:13:28,160 --> 00:13:28,880
And this would be.

240
00:13:28,880 --> 00:13:31,920
2022 is really looking like a spectacular year

241
00:13:31,920 --> 00:13:34,240
in terms of the number of neural toys

242
00:13:34,240 --> 00:13:35,440
that are coming to our hands

243
00:13:35,440 --> 00:13:39,200
to build a lot of tools and to be able to touch them.

244
00:13:39,200 --> 00:13:40,160
Now it's your turn.

245
00:13:40,160 --> 00:13:41,360
What can you do with this?

246
00:13:41,360 --> 00:13:44,240
Well, you can build a lot of super interesting things.

247
00:13:44,240 --> 00:13:47,040
You can connect, for example, Whisper with Stable Diffusion

248
00:13:47,040 --> 00:13:50,720
so that you can ask it to generate a picture.

249
00:13:50,720 --> 00:13:53,840
Or you can, for example, take all your classes at the university

250
00:13:53,840 --> 00:13:56,640
or all the work meetings, transcribe them,

251
00:13:56,640 --> 00:13:58,720
create a huge bank of transcriptions

252
00:13:58,720 --> 00:14:01,600
and then with the GPT-3 API make a chatbot

253
00:14:01,600 --> 00:14:04,160
that allows you to consult, ask questions and answers

254
00:14:04,160 --> 00:14:05,920
about all that source of information.

255
00:14:05,920 --> 00:14:07,360
For example, something I want to do

256
00:14:07,360 --> 00:14:09,920
is take all the videos from my YouTube channel

257
00:14:09,920 --> 00:14:12,880
and transcribe them, generate good quality subtitles

258
00:14:12,880 --> 00:14:14,480
both in Spanish and in English

259
00:14:14,480 --> 00:14:16,560
and be able to do statistics and consultations

260
00:14:16,560 --> 00:14:19,760
of how many times I have said, for example, the word machine learning.

261
00:14:19,760 --> 00:14:22,560
There are a lot of applications that you can start building,

262
00:14:22,560 --> 00:14:26,800
that you can start creating by combining all these technologies.

263
00:14:26,800 --> 00:14:28,080
There is also a barking dog in the background

264
00:14:28,080 --> 00:14:29,520
that was bothering me a lot.

265
00:14:29,520 --> 00:14:30,800
Well, what I was saying,

266
00:14:30,800 --> 00:14:33,920
that you can create a lot of things and there is a lot to do.

267
00:14:33,920 --> 00:14:36,400
From here, from this channel, we will continue to do experiments

268
00:14:36,400 --> 00:14:37,360
with this technology.

269
00:14:37,360 --> 00:14:39,600
I will continue to bring new tools

270
00:14:39,600 --> 00:14:42,000
so if you haven't done it yet, subscribe,

271
00:14:42,000 --> 00:14:44,720
hit the bell so you always get notifications

272
00:14:44,720 --> 00:14:45,840
that there is a new video

273
00:14:45,840 --> 00:14:47,600
and if you want to support all this content,

274
00:14:47,600 --> 00:14:50,320
you already know that you can do it through Patreon

275
00:14:50,320 --> 00:14:51,840
below in the description box.

276
00:14:51,840 --> 00:14:54,000
You have a couple of videos around here that are super interesting,

277
00:14:54,000 --> 00:14:55,840
I don't know which ones they are, but they are super interesting,

278
00:14:55,840 --> 00:14:56,880
take a look at them

279
00:14:56,880 --> 00:14:58,880
and see you with more artificial intelligence,

280
00:14:58,880 --> 00:15:10,880
guys, girls, in the next video.

